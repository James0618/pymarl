import torch
import torch.nn as nn
import torch.nn.functional as F


class TransitionModel(nn.Module):
    def __init__(self, observation_shape, args):
        """
        first, take the hidden state as the agents' state,
        and, the rnn output the prediction of observations.
        """
        super(TransitionModel, self).__init__()
        self.args = args

        # observation here contain "observation" of agents and their actions
        self.from_observations = nn.Sequential(
            nn.Linear(observation_shape, args.rnn_hidden_dim),
            nn.ReLU(),
            nn.Linear(args.rnn_hidden_dim, args.rnn_hidden_dim // 2)
        )
        self.from_actions = nn.Sequential(
            nn.Linear(args.n_actions, args.rnn_hidden_dim),
            nn.ReLU(),
            nn.Linear(args.rnn_hidden_dim, args.rnn_hidden_dim // 4)
        )
        self.from_opponent_actions = nn.Linear(args.latent_action_shape, args.rnn_hidden_dim // 4)

        self.features = nn.Sequential(
            nn.Linear(args.rnn_hidden_dim, args.rnn_hidden_dim),
            nn.ReLU(),
            nn.Linear(args.rnn_hidden_dim, args.rnn_hidden_dim)
        )

        self.transition = nn.GRUCell(args.rnn_hidden_dim, args.rnn_hidden_dim)

        # predict the "observation" of agents and state value
        self.pred_observation = nn.Sequential(
            nn.Linear(args.rnn_hidden_dim, args.rnn_hidden_dim),
            nn.ReLU(),
            nn.Linear(args.rnn_hidden_dim, observation_shape)
        )
        self.pred_reward = nn.Linear(args.rnn_hidden_dim, 1)

    def forward(self, observations, hidden_state, actions, opponent_actions):
        from_observations = F.relu(self.from_observations(observations)).reshape(-1, self.args.rnn_hidden_dim // 2)
        from_actions = F.relu(self.from_actions(actions)).reshape(-1, self.args.rnn_hidden_dim // 4)
        from_opponent_actions = F.relu(self.from_opponent_actions(
            opponent_actions)).reshape(-1, self.args.rnn_hidden_dim // 4)
        from_all_actions = torch.cat((from_actions, from_opponent_actions), dim=-1)

        observations_and_actions = torch.cat((from_observations, from_all_actions), dim=-1)
        features = F.relu(self.features(observations_and_actions)).reshape(-1, self.args.rnn_hidden_dim)
        hidden_state = hidden_state.reshape(-1, self.args.rnn_hidden_dim)

        next_hidden_state = self.transition(features, hidden_state).reshape(-1, self.args.n_actions,
                                                                            self.args.rnn_hidden_dim)
        pred_reward = self.pred_reward(next_hidden_state)
        pred_observation = self.pred_observation(next_hidden_state)

        return pred_observation, pred_reward, next_hidden_state

    def init_hidden(self):
        # make hidden states on same device as model
        return torch.zeros(1, self.args.rnn_hidden_dim).cuda()


class OpponentModel(nn.Module):
    def __init__(self, input_shape, args):
        """
        take the state generated by transition model as opponents' converted state,
        and transfer the opponents' actions
        """
        super(OpponentModel, self).__init__()
        self.args = args

        self.opponent = nn.Sequential(
            nn.Linear(input_shape, args.rnn_hidden_dim),
            nn.ReLU(),
            nn.Linear(args.rnn_hidden_dim, args.latent_action_shape),
        )

    def forward(self, agent_inputs, last_agent_inputs):
        # TODO: Add GMM to the opponent model!
        diff_obs = agent_inputs - last_agent_inputs
        test = diff_obs.cpu().numpy()
        latent_actions = self.opponent(diff_obs)

        return latent_actions


class StateEstimation(nn.Module):
    def __init__(self, observation_shape, args):
        super(StateEstimation, self).__init__()
        self.args = args

        self.estimate_state = nn.Sequential(
            nn.Linear(args.rnn_hidden_dim + observation_shape, args.rnn_hidden_dim),
            nn.ReLU(),
            nn.Linear(args.rnn_hidden_dim, args.state_shape)
        )
        self.estimate_value = nn.Linear(args.state_shape, 1)

    def forward(self, hidden_state, observation):
        # hidden_state = hidden_state.reshape(-1, self.args.rnn_hidden_dim)
        inputs = torch.cat((hidden_state, observation), dim=-1)

        state = F.relu(self.estimate_state(inputs))
        state_value = self.estimate_value(state)

        return state_value
